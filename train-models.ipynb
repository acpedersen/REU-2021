{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g/g01107/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, cohen_kappa_score, precision_score, recall_score, \\\n",
    "    precision_recall_curve\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import base_dir\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe  generated in analye-data.ipynb\n",
    "df = pd.read_json(\"./Trec_data/processed.json\", orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventID</th>\n",
       "      <th>eventType</th>\n",
       "      <th>postID</th>\n",
       "      <th>postCategories</th>\n",
       "      <th>postPriority</th>\n",
       "      <th>postText</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1231307896362807296</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Flood Warning: River Severn at Hanley Castle a...</td>\n",
       "      <td>[flood, february]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1231569665043976192</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Flood Warning: River Ouse at Naburn Lock 12:46...</td>\n",
       "      <td>[flood, naburn_lock, february]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1232264304067477504</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Our Assistant Director of Care and Support kin...</td>\n",
       "      <td>[assistant, director, care, support, kindly, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1232070602778959872</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>@hollywills please can you help support @HopeR...</td>\n",
       "      <td>[help, support, following, recent, flooding, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1232648900105965568</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Police order 'immediate evacuation' in Shropsh...</td>\n",
       "      <td>[police, order, flooding, send]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91510</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1155430270457323520</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Flood Alert: River Ecclesbourne in Derbyshire ...</td>\n",
       "      <td>[flood, alert, river]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91511</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1156993824591417344</td>\n",
       "      <td>[Location, EmergingThreats, MultimediaShare, N...</td>\n",
       "      <td>High</td>\n",
       "      <td>Dam at Whaley Bridge in Peak District threaten...</td>\n",
       "      <td>[peak, district, threaten, burst, gofh, pb, nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91512</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1157020257388769280</td>\n",
       "      <td>[ThirdPartyObservation, Location, MultimediaSh...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Floods in Whaley Bridge today.\\nhttps://t.co/7...</td>\n",
       "      <td>[flood, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91513</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1156926115069485056</td>\n",
       "      <td>[MovePeople, ThirdPartyObservation, Location, ...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Evacuation of Whaley Bridge | Derbyshire Const...</td>\n",
       "      <td>[evacuation, constabulary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91514</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1157001345649532928</td>\n",
       "      <td>[Hashtags, Sentiment]</td>\n",
       "      <td>Low</td>\n",
       "      <td>@itvnews Praying all are safe #WhaleyBridge</td>\n",
       "      <td>[pray, safe]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91515 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eventID eventType               postID  \\\n",
       "0                stormJorge2020   typhoon  1231307896362807296   \n",
       "1                stormJorge2020   typhoon  1231569665043976192   \n",
       "2                stormJorge2020   typhoon  1232264304067477504   \n",
       "3                stormJorge2020   typhoon  1232070602778959872   \n",
       "4                stormJorge2020   typhoon  1232648900105965568   \n",
       "...                         ...       ...                  ...   \n",
       "91510  whaleyBridgeCollapse2020     flood  1155430270457323520   \n",
       "91511  whaleyBridgeCollapse2020     flood  1156993824591417344   \n",
       "91512  whaleyBridgeCollapse2020     flood  1157020257388769280   \n",
       "91513  whaleyBridgeCollapse2020     flood  1156926115069485056   \n",
       "91514  whaleyBridgeCollapse2020     flood  1157001345649532928   \n",
       "\n",
       "                                          postCategories postPriority  \\\n",
       "0                                           [Irrelevant]          Low   \n",
       "1                                           [Irrelevant]          Low   \n",
       "2                                           [Irrelevant]          Low   \n",
       "3                                           [Irrelevant]          Low   \n",
       "4                                           [Irrelevant]          Low   \n",
       "...                                                  ...          ...   \n",
       "91510                                       [Irrelevant]          Low   \n",
       "91511  [Location, EmergingThreats, MultimediaShare, N...         High   \n",
       "91512  [ThirdPartyObservation, Location, MultimediaSh...          Low   \n",
       "91513  [MovePeople, ThirdPartyObservation, Location, ...     Critical   \n",
       "91514                              [Hashtags, Sentiment]          Low   \n",
       "\n",
       "                                                postText  \\\n",
       "0      Flood Warning: River Severn at Hanley Castle a...   \n",
       "1      Flood Warning: River Ouse at Naburn Lock 12:46...   \n",
       "2      Our Assistant Director of Care and Support kin...   \n",
       "3      @hollywills please can you help support @HopeR...   \n",
       "4      Police order 'immediate evacuation' in Shropsh...   \n",
       "...                                                  ...   \n",
       "91510  Flood Alert: River Ecclesbourne in Derbyshire ...   \n",
       "91511  Dam at Whaley Bridge in Peak District threaten...   \n",
       "91512  Floods in Whaley Bridge today.\\nhttps://t.co/7...   \n",
       "91513  Evacuation of Whaley Bridge | Derbyshire Const...   \n",
       "91514        @itvnews Praying all are safe #WhaleyBridge   \n",
       "\n",
       "                                          processed_text  \n",
       "0                                      [flood, february]  \n",
       "1                         [flood, naburn_lock, february]  \n",
       "2      [assistant, director, care, support, kindly, l...  \n",
       "3      [help, support, following, recent, flooding, c...  \n",
       "4                        [police, order, flooding, send]  \n",
       "...                                                  ...  \n",
       "91510                              [flood, alert, river]  \n",
       "91511  [peak, district, threaten, burst, gofh, pb, nc...  \n",
       "91512                                     [flood, today]  \n",
       "91513                         [evacuation, constabulary]  \n",
       "91514                                       [pray, safe]  \n",
       "\n",
       "[91515 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Generate Heldout Events`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['typhoon' 'storm' 'wildfire' 'covid' 'flood' 'bombing' 'shooting'\n",
      " 'earthquake' 'explosion' 'hostage' 'fire' 'tornado']\n"
     ]
    }
   ],
   "source": [
    "eventTypes = df['eventType'].unique()\n",
    "print(eventTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heldout_events = pd.DataFrame(columns=['eventID'])\n",
    "\n",
    "#Choose heldout event and saves in the heldout_events dataframe\n",
    "for event in eventTypes:\n",
    "    crises = df.loc[df['eventType']==event]['eventID'].unique()\n",
    "    heldout_events.loc[event]=[crises[random.choice(np.arange(crises.size))]]\n",
    "\n",
    "heldout_events.to_json('./Trec_data/heldout_events.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bombing</th>\n",
       "      <td>bostonBombings2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>covidHouston2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>philippinesEarthquake2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explosion</th>\n",
       "      <td>beirutExplosion2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>sanFranciscoPierFire2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flood</th>\n",
       "      <td>albertaFloods2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hostage</th>\n",
       "      <td>virraMallHostageSituation2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shooting</th>\n",
       "      <td>brooklynBlockPartyShooting2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>southeastTornadoOutbreak2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tornado</th>\n",
       "      <td>tennesseeTornadoOutbreak2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typhoon</th>\n",
       "      <td>stormCiara2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wildfire</th>\n",
       "      <td>siberianWildfires2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   eventID\n",
       "bombing                 bostonBombings2013\n",
       "covid                     covidHouston2020\n",
       "earthquake       philippinesEarthquake2019\n",
       "explosion              beirutExplosion2020\n",
       "fire              sanFranciscoPierFire2020\n",
       "flood                    albertaFloods2013\n",
       "hostage      virraMallHostageSituation2020\n",
       "shooting    brooklynBlockPartyShooting2020\n",
       "storm         southeastTornadoOutbreak2020\n",
       "tornado       tennesseeTornadoOutbreak2020\n",
       "typhoon                     stormCiara2020\n",
       "wildfire             siberianWildfires2020"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple read to keep the index by events\n",
    "heldout_events = pd.read_json('./Trec_data/heldout_events.json')\n",
    "heldout_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Model Related Methods`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(data, column, heldout_ids):\n",
    "    training = data.loc[~data[column].isin(heldout_ids)]\n",
    "    \n",
    "    return training\n",
    "\n",
    "def test_data(data, column, heldout_ids):\n",
    "    test = data.loc[data[column].isin(heldout_ids)]\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(data, features, target, modelParameters):\n",
    "    \n",
    "    model = RandomForestClassifier(**modelParameters)\n",
    "    model.fit(data[features].to_numpy(), data[target].to_numpy())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_model_by_events(data, features, target, modelParameters):\n",
    "    modelList = pd.DataFrame(columns=['model'])\n",
    "    for event in tqdm(eventTypes):\n",
    "        #Create training and test dataframe\n",
    "        training = train_data(df, 'eventID', heldout_crisis)\n",
    "        \n",
    "        #generate event specific model\n",
    "        model = generate_model(training, features, target, modelParameters)\n",
    "        \n",
    "        #Add model to list\n",
    "        modelList.loc[event] = [model]\n",
    "        \n",
    "        #print('')\n",
    "    return modelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data, features, target, model):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Generate Generic Variables`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78746, 7)\n"
     ]
    }
   ],
   "source": [
    "features = ['vectorized_text'] #put in list of columns you want it to be trained on (Other features etc.)\n",
    "features.append(other_features_names)\n",
    "\n",
    "rf_params = {\n",
    "    'random_state': 1337,\n",
    "    'class_weight': 'balanced',\n",
    "    'n_estimators': 128, \n",
    "    'n_jobs': -1,\n",
    "    'max_depth': 50,\n",
    "    'max_features': 14,\n",
    "    'min_samples_leaf': 33,\n",
    "    'min_samples_split': 96,\n",
    "}\n",
    "\n",
    "#Training data withholding all heldout events for general models\n",
    "generalTraining = train_data(df, 'eventID', heldout_events['eventID'].tolist())\n",
    "print(generalTraining.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Generate postPriority Models`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list(['flood', 'february'])],\n",
       "       [list(['flood', 'naburn_lock', 'february'])],\n",
       "       [list(['assistant', 'director', 'care', 'support', 'kindly', 'lend', 'local', 'resilience', 'forum', 'colleague', 'kitchen', 'yesterday', 'assist', 'flooding', 'selby', 'yesterday'])],\n",
       "       ...,\n",
       "       [list(['flood', 'today'])],\n",
       "       [list(['evacuation', 'constabulary'])],\n",
       "       [list(['pray', 'safe'])]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalTraining[features].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-37acfc240596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#generate general model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenPrioModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneralTraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'postPriority'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#generate event specific models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#specPrioModels = generate_model_by_events(df, features, 'postPriority', rf_params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-49cfc334a0e4>\u001b[0m in \u001b[0;36mgenerate_model\u001b[0;34m(data, features, target, modelParameters)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodelParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cad/linux/anaconda3.8/anaconda/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cad/linux/anaconda3.8/anaconda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/afs/cad/linux/anaconda3.8/anaconda/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#generate general model\n",
    "genPrioModel = generate_model(generalTraining, features, 'postPriority', rf_params)\n",
    "\n",
    "#generate event specific models\n",
    "#specPrioModels = generate_model_by_events(df, features, 'postPriority', rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save postPriority models\n",
    "model.save(model/postPriority.h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Generate postCategories Models`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate general model\n",
    "catLabels = ['postCategories'] #target\n",
    "genCatModel =  generate_model(generalTraining, features, catLabels, rf_params)\n",
    "\n",
    "#generate event specific models\n",
    "specCatModels = generate_model_by_events(df, features, catLabels, rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save postCategories models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Test All Models`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load All Models\n",
    "genPrioModel\n",
    "specPrioModels\n",
    "genCatModel\n",
    "specCatModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test postPriority models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test postCategories models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
