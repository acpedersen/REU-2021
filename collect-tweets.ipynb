{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g/g01107/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, cohen_kappa_score, precision_score, recall_score, \\\n",
    "    precision_recall_curve\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from sklearn.base import clone\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import base_dir\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/g/g01107/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/g/g01107/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS\n",
    "import re\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseJsonPath = '/research/cbuntain/datasets/twitter/trecis/allEventJson/'\n",
    "baseFileName = 'TRECIS-CTIT-H-*.json.gz' #* is to be replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventID</th>\n",
       "      <th>eventType</th>\n",
       "      <th>postID</th>\n",
       "      <th>postCategories</th>\n",
       "      <th>postPriority</th>\n",
       "      <th>postText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1231307896362807298</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Flood Warning: River Severn at Hanley Castle a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1231569665043976192</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Flood Warning: River Ouse at Naburn Lock 12:46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1232264304067477504</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Our Assistant Director of Care and Support kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1232070602778959872</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>@hollywills please can you help support @HopeR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stormJorge2020</td>\n",
       "      <td>typhoon</td>\n",
       "      <td>1232648900105965568</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Police order 'immediate evacuation' in Shropsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91510</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1155430270457323520</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Flood Alert: River Ecclesbourne in Derbyshire ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91511</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1156993824591417346</td>\n",
       "      <td>[Location, EmergingThreats, MultimediaShare, N...</td>\n",
       "      <td>High</td>\n",
       "      <td>Dam at Whaley Bridge in Peak District threaten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91512</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1157020257388769280</td>\n",
       "      <td>[ThirdPartyObservation, Location, MultimediaSh...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Floods in Whaley Bridge today.\\nhttps://t.co/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91513</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1156926115069485056</td>\n",
       "      <td>[MovePeople, ThirdPartyObservation, Location, ...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Evacuation of Whaley Bridge | Derbyshire Const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91514</th>\n",
       "      <td>whaleyBridgeCollapse2020</td>\n",
       "      <td>flood</td>\n",
       "      <td>1157001345649532935</td>\n",
       "      <td>[Hashtags, Sentiment]</td>\n",
       "      <td>Low</td>\n",
       "      <td>@itvnews Praying all are safe #WhaleyBridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91515 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eventID eventType               postID  \\\n",
       "0                stormJorge2020   typhoon  1231307896362807298   \n",
       "1                stormJorge2020   typhoon  1231569665043976192   \n",
       "2                stormJorge2020   typhoon  1232264304067477504   \n",
       "3                stormJorge2020   typhoon  1232070602778959872   \n",
       "4                stormJorge2020   typhoon  1232648900105965568   \n",
       "...                         ...       ...                  ...   \n",
       "91510  whaleyBridgeCollapse2020     flood  1155430270457323520   \n",
       "91511  whaleyBridgeCollapse2020     flood  1156993824591417346   \n",
       "91512  whaleyBridgeCollapse2020     flood  1157020257388769280   \n",
       "91513  whaleyBridgeCollapse2020     flood  1156926115069485056   \n",
       "91514  whaleyBridgeCollapse2020     flood  1157001345649532935   \n",
       "\n",
       "                                          postCategories postPriority  \\\n",
       "0                                           [Irrelevant]          Low   \n",
       "1                                           [Irrelevant]          Low   \n",
       "2                                           [Irrelevant]          Low   \n",
       "3                                           [Irrelevant]          Low   \n",
       "4                                           [Irrelevant]          Low   \n",
       "...                                                  ...          ...   \n",
       "91510                                       [Irrelevant]          Low   \n",
       "91511  [Location, EmergingThreats, MultimediaShare, N...         High   \n",
       "91512  [ThirdPartyObservation, Location, MultimediaSh...          Low   \n",
       "91513  [MovePeople, ThirdPartyObservation, Location, ...     Critical   \n",
       "91514                              [Hashtags, Sentiment]          Low   \n",
       "\n",
       "                                                postText  \n",
       "0      Flood Warning: River Severn at Hanley Castle a...  \n",
       "1      Flood Warning: River Ouse at Naburn Lock 12:46...  \n",
       "2      Our Assistant Director of Care and Support kin...  \n",
       "3      @hollywills please can you help support @HopeR...  \n",
       "4      Police order 'immediate evacuation' in Shropsh...  \n",
       "...                                                  ...  \n",
       "91510  Flood Alert: River Ecclesbourne in Derbyshire ...  \n",
       "91511  Dam at Whaley Bridge in Peak District threaten...  \n",
       "91512  Floods in Whaley Bridge today.\\nhttps://t.co/7...  \n",
       "91513  Evacuation of Whaley Bridge | Derbyshire Const...  \n",
       "91514        @itvnews Praying all are safe #WhaleyBridge  \n",
       "\n",
       "[91515 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Opens the data and reorganizes it by tweets instead of by events\n",
    "with open('./Trec_data/labeled_by_event.json') as f:\n",
    "    js = json.load(f)\n",
    "df = json_normalize(data=js['events'], record_path='tweets')\n",
    "df.to_json('./Trec_data/labeled.json', orient='records', lines=True)\n",
    "\n",
    "df['postID'] = df['postID'].astype(int)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run through each json file and see if it relates\n",
    "recordCount = 123\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(1, recordCount), position=0, leave=True):\n",
    "    filepath = baseJsonPath + baseFileName.replace('*', str(i).zfill(3))\n",
    "    jsonDF = pd.read_json(filepath, orient='records',lines=True)\n",
    "    temp_df = pd.merge(df, jsonDF, how='inner', left_on='postID', right_on='id')\n",
    "    full_df = pd.concat([full_df, temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save full_df\n",
    "full_df.to_json('./Trec_data/full_comb_labeled.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>contributorsIDs</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>created_at</th>\n",
       "      <th>currentUserRetweetId</th>\n",
       "      <th>displayTextRangeEnd</th>\n",
       "      <th>displayTextRangeStart</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>symbolEntities</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>topic</th>\n",
       "      <th>truncated</th>\n",
       "      <th>urlEntities</th>\n",
       "      <th>user</th>\n",
       "      <th>userMentionEntities</th>\n",
       "      <th>withheld_in_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-06-12 02:07:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [{'tex...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>None</td>\n",
       "      <td>The High Park fire west of Fort Collins, #CO h...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TRECIS-CTIT-H-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'location': 'United States', 'default_profile...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-105.1348135...</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-06-26 22:22:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [{'tex...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>None</td>\n",
       "      <td>Pic of the #FlagstaffFire in boulder from our ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TRECIS-CTIT-H-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'location': 'Erie, Co', 'default_profile': Tr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-06-11 22:34:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [{'tex...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @CBSDenver: The copter is on the way to the...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TRECIS-CTIT-H-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'location': 'Boulder, Colorado', 'default_pro...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-06-24 23:05:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [], 'u...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>None</td>\n",
       "      <td>I have it on good authority that most of Color...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TRECIS-CTIT-H-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'location': 'Louisville, KY', 'default_profil...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2012-06-26 22:29:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [{'tex...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @ColoradoRapids: Photo of #FlagStaffFire in...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TRECIS-CTIT-H-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'location': 'Denver', 'default_profile': Fals...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101108</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-04 17:18:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>None</td>\n",
       "      <td>Putnam County: Cookeville area tornado victims...</td>\n",
       "      <td>2020-03-04 17:18:19.342</td>\n",
       "      <td>TRECIS-CTIT-H-120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 825386050243682311, 'id_str': '82538605...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-04 15:53:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>None</td>\n",
       "      <td>All Bad: Guy Gets Stuck 375 Ft High In A Crane...</td>\n",
       "      <td>2020-03-04 15:53:11.876</td>\n",
       "      <td>TRECIS-CTIT-H-120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 1192317385719648256, 'id_str': '1192317...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-04 18:36:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>Earth Catastrophe Resources, Nashville Storm f...</td>\n",
       "      <td>2020-03-04 18:36:46.758</td>\n",
       "      <td>TRECIS-CTIT-H-120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 1198906372659830784, 'id_str': '1198906...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-04 18:36:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>Earth Catastrophe Resources, Nashville Storm f...</td>\n",
       "      <td>2020-03-04 18:36:20.643</td>\n",
       "      <td>TRECIS-CTIT-H-120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 1198892581553393664, 'id_str': '1198892...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-04 20:30:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>BREAKING: @NWSNashville says there is at least...</td>\n",
       "      <td>2020-03-04 20:30:58.984</td>\n",
       "      <td>TRECIS-CTIT-H-120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 14838173, 'id_str': '14838173', 'name':...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101113 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        contributors contributorsIDs  \\\n",
       "0                NaN            None   \n",
       "1                NaN            None   \n",
       "2                NaN            None   \n",
       "3                NaN            None   \n",
       "4                NaN            None   \n",
       "...              ...             ...   \n",
       "101108           NaN            None   \n",
       "101109           NaN            None   \n",
       "101110           NaN            None   \n",
       "101111           NaN            None   \n",
       "101112           NaN            None   \n",
       "\n",
       "                                              coordinates createdAt  \\\n",
       "0                                                    None      None   \n",
       "1       {'type': 'Point', 'coordinates': [-105.1348135...      None   \n",
       "2                                                    None      None   \n",
       "3                                                    None      None   \n",
       "4                                                    None      None   \n",
       "...                                                   ...       ...   \n",
       "101108                                               None      None   \n",
       "101109                                               None      None   \n",
       "101110                                               None      None   \n",
       "101111                                               None      None   \n",
       "101112                                               None      None   \n",
       "\n",
       "                created_at  currentUserRetweetId  displayTextRangeEnd  \\\n",
       "0      2012-06-12 02:07:42                   NaN                  NaN   \n",
       "1      2012-06-26 22:22:32                   NaN                  NaN   \n",
       "2      2012-06-11 22:34:58                   NaN                  NaN   \n",
       "3      2012-06-24 23:05:37                   NaN                  NaN   \n",
       "4      2012-06-26 22:29:11                   NaN                  NaN   \n",
       "...                    ...                   ...                  ...   \n",
       "101108 2020-03-04 17:18:19                   NaN                  NaN   \n",
       "101109 2020-03-04 15:53:11                   NaN                  NaN   \n",
       "101110 2020-03-04 18:36:46                   NaN                  NaN   \n",
       "101111 2020-03-04 18:36:20                   NaN                  NaN   \n",
       "101112 2020-03-04 20:30:58                   NaN                  NaN   \n",
       "\n",
       "        displayTextRangeStart display_text_range  \\\n",
       "0                         NaN               None   \n",
       "1                         NaN               None   \n",
       "2                         NaN               None   \n",
       "3                         NaN               None   \n",
       "4                         NaN               None   \n",
       "...                       ...                ...   \n",
       "101108                    NaN               None   \n",
       "101109                    NaN               None   \n",
       "101110                    NaN               None   \n",
       "101111                    NaN               None   \n",
       "101112                    NaN               None   \n",
       "\n",
       "                                                 entities  ...  \\\n",
       "0       {'symbols': [], 'urls': [], 'hashtags': [{'tex...  ...   \n",
       "1       {'symbols': [], 'urls': [], 'hashtags': [{'tex...  ...   \n",
       "2       {'symbols': [], 'urls': [], 'hashtags': [{'tex...  ...   \n",
       "3       {'symbols': [], 'urls': [], 'hashtags': [], 'u...  ...   \n",
       "4       {'symbols': [], 'urls': [], 'hashtags': [{'tex...  ...   \n",
       "...                                                   ...  ...   \n",
       "101108  {'hashtags': [], 'urls': [{'url': 'https://t.c...  ...   \n",
       "101109  {'hashtags': [], 'urls': [{'url': 'https://t.c...  ...   \n",
       "101110  {'hashtags': [], 'urls': [{'url': 'https://t.c...  ...   \n",
       "101111  {'hashtags': [], 'urls': [{'url': 'https://t.c...  ...   \n",
       "101112  {'hashtags': [], 'urls': [{'url': 'https://t.c...  ...   \n",
       "\n",
       "                                                   source symbolEntities  \\\n",
       "0       <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...           None   \n",
       "1       <a href=\"http://twitter.com/download/iphone\" r...           None   \n",
       "2       <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...           None   \n",
       "3       <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...           None   \n",
       "4       <a href=\"http://twitter.com/download/iphone\" r...           None   \n",
       "...                                                   ...            ...   \n",
       "101108  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...           None   \n",
       "101109  <a href=\"http://twitter.com/download/iphone\" r...           None   \n",
       "101110  <a href=\"https://mobile.twitter.com\" rel=\"nofo...           None   \n",
       "101111  <a href=\"https://mobile.twitter.com\" rel=\"nofo...           None   \n",
       "101112  <a href=\"https://mobile.twitter.com\" rel=\"nofo...           None   \n",
       "\n",
       "                                                     text  \\\n",
       "0       The High Park fire west of Fort Collins, #CO h...   \n",
       "1       Pic of the #FlagstaffFire in boulder from our ...   \n",
       "2       RT @CBSDenver: The copter is on the way to the...   \n",
       "3       I have it on good authority that most of Color...   \n",
       "4       RT @ColoradoRapids: Photo of #FlagStaffFire in...   \n",
       "...                                                   ...   \n",
       "101108  Putnam County: Cookeville area tornado victims...   \n",
       "101109  All Bad: Guy Gets Stuck 375 Ft High In A Crane...   \n",
       "101110  Earth Catastrophe Resources, Nashville Storm f...   \n",
       "101111  Earth Catastrophe Resources, Nashville Storm f...   \n",
       "101112  BREAKING: @NWSNashville says there is at least...   \n",
       "\n",
       "                  timestamp_ms              topic  truncated  urlEntities  \\\n",
       "0                          NaT  TRECIS-CTIT-H-001        0.0         None   \n",
       "1                          NaT  TRECIS-CTIT-H-001        0.0         None   \n",
       "2                          NaT  TRECIS-CTIT-H-001        0.0         None   \n",
       "3                          NaT  TRECIS-CTIT-H-001        0.0         None   \n",
       "4                          NaT  TRECIS-CTIT-H-001        0.0         None   \n",
       "...                        ...                ...        ...          ...   \n",
       "101108 2020-03-04 17:18:19.342  TRECIS-CTIT-H-120        0.0         None   \n",
       "101109 2020-03-04 15:53:11.876  TRECIS-CTIT-H-120        0.0         None   \n",
       "101110 2020-03-04 18:36:46.758  TRECIS-CTIT-H-120        0.0         None   \n",
       "101111 2020-03-04 18:36:20.643  TRECIS-CTIT-H-120        0.0         None   \n",
       "101112 2020-03-04 20:30:58.984  TRECIS-CTIT-H-120        1.0         None   \n",
       "\n",
       "                                                     user userMentionEntities  \\\n",
       "0       {'location': 'United States', 'default_profile...                None   \n",
       "1       {'location': 'Erie, Co', 'default_profile': Tr...                None   \n",
       "2       {'location': 'Boulder, Colorado', 'default_pro...                None   \n",
       "3       {'location': 'Louisville, KY', 'default_profil...                None   \n",
       "4       {'location': 'Denver', 'default_profile': Fals...                None   \n",
       "...                                                   ...                 ...   \n",
       "101108  {'id': 825386050243682311, 'id_str': '82538605...                None   \n",
       "101109  {'id': 1192317385719648256, 'id_str': '1192317...                None   \n",
       "101110  {'id': 1198906372659830784, 'id_str': '1198906...                None   \n",
       "101111  {'id': 1198892581553393664, 'id_str': '1198892...                None   \n",
       "101112  {'id': 14838173, 'id_str': '14838173', 'name':...                None   \n",
       "\n",
       "       withheld_in_countries  \n",
       "0                       None  \n",
       "1                       None  \n",
       "2                       None  \n",
       "3                       None  \n",
       "4                       None  \n",
       "...                      ...  \n",
       "101108                  None  \n",
       "101109                  None  \n",
       "101110                  None  \n",
       "101111                  None  \n",
       "101112                  None  \n",
       "\n",
       "[101113 rows x 71 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_json(\"./Trec_data/full_comb_labeled.json\", orient='records',lines=True)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typhoon: 13 : 13\n",
      "['stormJorge2020' 'hurricaneBarry2020' 'joplinTornado2011'\n",
      " 'cycloneKenneth2019' 'tropicalStormCristobal2020' 'stormDennis2020'\n",
      " 'typhoonLekima2020' 'typhoonKrosa2020' 'typhoonHagupit2014'\n",
      " 'stormCiara2020' 'typhoonPablo2012' 'typhoonYolanda2013'\n",
      " 'hurricaneFlorence2018']\n",
      "['typhoonPablo2012' 'typhoonYolanda2013' 'joplinTornado2011'\n",
      " 'typhoonHagupit2014' 'hurricaneFlorence2018' 'cycloneKenneth2019'\n",
      " 'hurricaneBarry2020' 'typhoonLekima2020' 'typhoonKrosa2020'\n",
      " 'stormCiara2020' 'stormDennis2020' 'stormJorge2020'\n",
      " 'tropicalStormCristobal2020']\n",
      "storm: 2 : 2\n",
      "['tennesseeDerecho2020' 'southeastTornadoOutbreak2020']\n",
      "['southeastTornadoOutbreak2020' 'tennesseeDerecho2020']\n",
      "wildfire: 5 : 5\n",
      "['australiaBushfire2013' 'albertaWildfires2019' 'fireColorado2012'\n",
      " 'siberianWildfires2020' 'fireYMM2016']\n",
      "['fireColorado2012' 'australiaBushfire2013' 'fireYMM2016'\n",
      " 'albertaWildfires2019' 'siberianWildfires2020']\n",
      "covid: 10 : 10\n",
      "['covidNYC2020' 'covidHouston2020' 'covidDC2020' 'covidSeattle2020'\n",
      " 'covidPhoenix2020' 'covidJacksonville2020' 'covidWashingtonState2020'\n",
      " 'covidAtlanta2020' 'covidNewZealand2020' 'covidMelbourne2020']\n",
      "['covidNYC2020' 'covidDC2020' 'covidWashingtonState2020'\n",
      " 'covidAtlanta2020' 'covidHouston2020' 'covidJacksonville2020'\n",
      " 'covidPhoenix2020' 'covidSeattle2020' 'covidMelbourne2020'\n",
      " 'covidNewZealand2020']\n",
      "flood: 12 : 12\n",
      "['albertaFloods2013' 'keralaFloods2020' 'southAfricaFloods2019'\n",
      " 'edenvilleDamFailure2020' 'floodColorado2013' 'floodChoco2019'\n",
      " 'queenslandFloods2013' 'myanmarFloods2020' 'manilaFloods2013'\n",
      " 'baltimoreFlashFlood2020' 'philipinnesFloods2012'\n",
      " 'whaleyBridgeCollapse2020']\n",
      "['floodColorado2013' 'philipinnesFloods2012' 'albertaFloods2013'\n",
      " 'manilaFloods2013' 'queenslandFloods2013' 'floodChoco2019'\n",
      " 'southAfricaFloods2019' 'baltimoreFlashFlood2020' 'keralaFloods2020'\n",
      " 'myanmarFloods2020' 'whaleyBridgeCollapse2020' 'edenvilleDamFailure2020']\n",
      "bombing: 3 : 3\n",
      "['westTexasExplosion2013' 'bostonBombings2013' 'parisAttacks2015']\n",
      "['westTexasExplosion2013' 'bostonBombings2013' 'parisAttacks2015']\n",
      "shooting: 10 : 10\n",
      "['daytonOhioShooting2020' 'gilroygarlicShooting2020'\n",
      " 'coloradoStemShooting2019' 'elPasoWalmartShooting2020'\n",
      " 'sandiegoSynagogueShooting2019' 'texasAMCommerceShooting2020'\n",
      " 'shootingDallas2017' 'laAirportShooting2013' 'flSchoolShooting2018'\n",
      " 'brooklynBlockPartyShooting2020']\n",
      "['laAirportShooting2013' 'flSchoolShooting2018' 'shootingDallas2017'\n",
      " 'coloradoStemShooting2019' 'sandiegoSynagogueShooting2019'\n",
      " 'brooklynBlockPartyShooting2020' 'daytonOhioShooting2020'\n",
      " 'elPasoWalmartShooting2020' 'gilroygarlicShooting2020'\n",
      " 'texasAMCommerceShooting2020']\n",
      "earthquake: 11 : 11\n",
      "['earthquakeBohol2013' 'guatemalaEarthquake2012' 'chileEarthquake2014'\n",
      " 'papuaNewguineaEarthquake2020' 'earthquakeCalifornia2014'\n",
      " 'nepalEarthquake2015' 'italyEarthquakes2012' 'indonesiaEarthquake2020'\n",
      " 'philippinesEarthquake2019' 'athensEarthquake2020'\n",
      " 'costaRicaEarthquake2012']\n",
      "['costaRicaEarthquake2012' 'guatemalaEarthquake2012'\n",
      " 'italyEarthquakes2012' 'chileEarthquake2014' 'nepalEarthquake2015'\n",
      " 'earthquakeCalifornia2014' 'earthquakeBohol2013'\n",
      " 'philippinesEarthquake2019' 'athensEarthquake2020'\n",
      " 'indonesiaEarthquake2020' 'papuaNewguineaEarthquake2020']\n",
      "explosion: 2 : 2\n",
      "['beirutExplosion2020' 'houstonExplosion2020']\n",
      "['houstonExplosion2020' 'beirutExplosion2020']\n",
      "hostage: 1 : 1\n",
      "['virraMallHostageSituation2020']\n",
      "['virraMallHostageSituation2020']\n",
      "fire: 1 : 1\n",
      "['sanFranciscoPierFire2020']\n",
      "['sanFranciscoPierFire2020']\n",
      "tornado: 1 : 1\n",
      "['tennesseeTornadoOutbreak2020']\n",
      "['tennesseeTornadoOutbreak2020']\n"
     ]
    }
   ],
   "source": [
    "eventTypes = df['eventType'].unique()\n",
    "for event in eventTypes:\n",
    "    eventsDF = df.loc[df['eventType']==event]['eventID'].unique()\n",
    "    events = full_df.loc[full_df['eventType']==event]['eventID'].unique()\n",
    "    print(event + ': ' + str(eventsDF.size) + ' : ' + str(events.size))\n",
    "    print(eventsDF)\n",
    "    print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postText\n",
      "\n",
      "fireColorado2012: 100.0%\n",
      "costaRicaEarthquake2012: 100.0%\n",
      "floodColorado2013: 100.0%\n",
      "typhoonPablo2012: 100.0%\n",
      "laAirportShooting2013: 100.0%\n",
      "westTexasExplosion2013: 100.0%\n",
      "guatemalaEarthquake2012: 100.0%\n",
      "italyEarthquakes2012: 100.0%\n",
      "philipinnesFloods2012: 100.0%\n",
      "albertaFloods2013: 100.0%\n",
      "australiaBushfire2013: 100.0%\n",
      "bostonBombings2013: 100.0%\n",
      "manilaFloods2013: 100.0%\n",
      "queenslandFloods2013: 100.0%\n",
      "typhoonYolanda2013: 100.0%\n",
      "joplinTornado2011: 100.0%\n",
      "chileEarthquake2014: 100.0%\n",
      "typhoonHagupit2014: 100.0%\n",
      "nepalEarthquake2015: 100.0%\n",
      "flSchoolShooting2018: 100.0%\n",
      "parisAttacks2015: 100.0%\n",
      "\n",
      "text\n",
      "\n",
      "covidNYC2020: 100.0%\n",
      "covidDC2020: 100.0%\n",
      "covidWashingtonState2020: 100.0%\n",
      "houstonExplosion2020: 100.0%\n",
      "texasAMCommerceShooting2020: 100.0%\n",
      "southeastTornadoOutbreak2020: 100.0%\n",
      "stormCiara2020: 100.0%\n",
      "stormDennis2020: 100.0%\n",
      "virraMallHostageSituation2020: 100.0%\n",
      "stormJorge2020: 100.0%\n",
      "tennesseeTornadoOutbreak2020: 100.0%\n",
      "tennesseeDerecho2020: 100.0%\n",
      "edenvilleDamFailure2020: 100.0%\n",
      "sanFranciscoPierFire2020: 100.0%\n",
      "tropicalStormCristobal2020: 100.0%\n",
      "beirutExplosion2020: 100.0%\n",
      "covidAtlanta2020: 100.0%\n",
      "covidHouston2020: 100.0%\n",
      "covidJacksonville2020: 100.0%\n",
      "covidPhoenix2020: 100.0%\n",
      "covidSeattle2020: 100.0%\n",
      "covidMelbourne2020: 100.0%\n",
      "covidNewZealand2020: 100.0%\n",
      "\n",
      "full_text\n",
      "\n",
      "fireColorado2012: 100.0%\n",
      "costaRicaEarthquake2012: 100.0%\n",
      "floodColorado2013: 100.0%\n",
      "typhoonPablo2012: 100.0%\n",
      "laAirportShooting2013: 100.0%\n",
      "westTexasExplosion2013: 100.0%\n",
      "guatemalaEarthquake2012: 100.0%\n",
      "italyEarthquakes2012: 100.0%\n",
      "philipinnesFloods2012: 100.0%\n",
      "albertaFloods2013: 100.0%\n",
      "australiaBushfire2013: 100.0%\n",
      "bostonBombings2013: 100.0%\n",
      "manilaFloods2013: 100.0%\n",
      "queenslandFloods2013: 100.0%\n",
      "typhoonYolanda2013: 100.0%\n",
      "joplinTornado2011: 100.0%\n",
      "chileEarthquake2014: 100.0%\n",
      "typhoonHagupit2014: 100.0%\n",
      "nepalEarthquake2015: 100.0%\n",
      "flSchoolShooting2018: 100.0%\n",
      "parisAttacks2015: 100.0%\n",
      "floodChoco2019: 100.0%\n",
      "earthquakeCalifornia2014: 100.0%\n",
      "earthquakeBohol2013: 100.0%\n",
      "hurricaneFlorence2018: 100.0%\n",
      "albertaWildfires2019: 100.0%\n",
      "cycloneKenneth2019: 100.0%\n",
      "southAfricaFloods2019: 100.0%\n",
      "philippinesEarthquake2019: 100.0%\n",
      "coloradoStemShooting2019: 100.0%\n",
      "sandiegoSynagogueShooting2019: 100.0%\n",
      "athensEarthquake2020: 100.0%\n",
      "baltimoreFlashFlood2020: 100.0%\n",
      "brooklynBlockPartyShooting2020: 100.0%\n",
      "daytonOhioShooting2020: 100.0%\n",
      "elPasoWalmartShooting2020: 100.0%\n",
      "gilroygarlicShooting2020: 100.0%\n",
      "hurricaneBarry2020: 100.0%\n",
      "indonesiaEarthquake2020: 100.0%\n",
      "keralaFloods2020: 100.0%\n",
      "myanmarFloods2020: 100.0%\n",
      "papuaNewguineaEarthquake2020: 100.0%\n",
      "siberianWildfires2020: 100.0%\n",
      "typhoonLekima2020: 100.0%\n",
      "typhoonKrosa2020: 100.0%\n",
      "whaleyBridgeCollapse2020: 100.0%\n",
      "houstonExplosion2020: 100.0%\n",
      "texasAMCommerceShooting2020: 100.0%\n",
      "southeastTornadoOutbreak2020: 100.0%\n",
      "tennesseeDerecho2020: 100.0%\n",
      "sanFranciscoPierFire2020: 100.0%\n",
      "covidPhoenix2020: 100.0%\n",
      "tennesseeTornadoOutbreak2020: 100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nullTexts = ['postText', 'text', 'full_text']\n",
    "\n",
    "for textVar in nullTexts:\n",
    "    print(textVar)\n",
    "    print()\n",
    "    events = full_df.loc[pd.isna(full_df[textVar])].eventID.unique()\n",
    "    for event in events:\n",
    "        total = full_df.loc[pd.isna(full_df[textVar]) & (full_df['eventID']==event)].size\n",
    "        partial = full_df.loc[pd.isna(full_df[textVar]) & (full_df['eventID']==event)].size\n",
    "        percentage = 100*partial/total\n",
    "        print(event + ': ' + str(percentage) +'%')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               postText   text full_text\n",
      "fireColorado2012                   True  False      True\n",
      "costaRicaEarthquake2012            True  False      True\n",
      "floodColorado2013                  True  False      True\n",
      "typhoonPablo2012                   True  False      True\n",
      "laAirportShooting2013              True  False      True\n",
      "westTexasExplosion2013             True  False      True\n",
      "guatemalaEarthquake2012            True  False      True\n",
      "italyEarthquakes2012               True  False      True\n",
      "philipinnesFloods2012              True  False      True\n",
      "albertaFloods2013                  True  False      True\n",
      "australiaBushfire2013              True  False      True\n",
      "bostonBombings2013                 True  False      True\n",
      "manilaFloods2013                   True  False      True\n",
      "queenslandFloods2013               True  False      True\n",
      "typhoonYolanda2013                 True  False      True\n",
      "joplinTornado2011                  True  False      True\n",
      "chileEarthquake2014                True  False      True\n",
      "typhoonHagupit2014                 True  False      True\n",
      "nepalEarthquake2015                True  False      True\n",
      "flSchoolShooting2018               True  False      True\n",
      "parisAttacks2015                   True  False      True\n",
      "covidNYC2020                      False   True     False\n",
      "covidDC2020                       False   True     False\n",
      "covidWashingtonState2020          False   True     False\n",
      "houstonExplosion2020              False   True      True\n",
      "texasAMCommerceShooting2020       False   True      True\n",
      "southeastTornadoOutbreak2020      False   True      True\n",
      "stormCiara2020                    False   True     False\n",
      "stormDennis2020                   False   True     False\n",
      "virraMallHostageSituation2020     False   True     False\n",
      "stormJorge2020                    False   True     False\n",
      "tennesseeTornadoOutbreak2020      False   True      True\n",
      "tennesseeDerecho2020              False   True      True\n",
      "edenvilleDamFailure2020           False   True     False\n",
      "sanFranciscoPierFire2020          False   True      True\n",
      "tropicalStormCristobal2020        False   True     False\n",
      "beirutExplosion2020               False   True     False\n",
      "covidAtlanta2020                  False   True     False\n",
      "covidHouston2020                  False   True     False\n",
      "covidJacksonville2020             False   True     False\n",
      "covidPhoenix2020                  False   True      True\n",
      "covidSeattle2020                  False   True     False\n",
      "covidMelbourne2020                False   True     False\n",
      "covidNewZealand2020               False   True     False\n",
      "floodChoco2019                    False  False      True\n",
      "earthquakeCalifornia2014          False  False      True\n",
      "earthquakeBohol2013               False  False      True\n",
      "hurricaneFlorence2018             False  False      True\n",
      "albertaWildfires2019              False  False      True\n",
      "cycloneKenneth2019                False  False      True\n",
      "southAfricaFloods2019             False  False      True\n",
      "philippinesEarthquake2019         False  False      True\n",
      "coloradoStemShooting2019          False  False      True\n",
      "sandiegoSynagogueShooting2019     False  False      True\n",
      "athensEarthquake2020              False  False      True\n",
      "baltimoreFlashFlood2020           False  False      True\n",
      "brooklynBlockPartyShooting2020    False  False      True\n",
      "daytonOhioShooting2020            False  False      True\n",
      "elPasoWalmartShooting2020         False  False      True\n",
      "gilroygarlicShooting2020          False  False      True\n",
      "hurricaneBarry2020                False  False      True\n",
      "indonesiaEarthquake2020           False  False      True\n",
      "keralaFloods2020                  False  False      True\n",
      "myanmarFloods2020                 False  False      True\n",
      "papuaNewguineaEarthquake2020      False  False      True\n",
      "siberianWildfires2020             False  False      True\n",
      "typhoonLekima2020                 False  False      True\n",
      "typhoonKrosa2020                  False  False      True\n",
      "whaleyBridgeCollapse2020          False  False      True\n"
     ]
    }
   ],
   "source": [
    "nullTexts = ['postText', 'text', 'full_text']\n",
    "nullTextDf = pd.DataFrame(columns = nullTexts)\n",
    "for textVar in nullTexts:\n",
    "    events = full_df.loc[pd.isna(full_df[textVar])].eventID.unique()\n",
    "    for event in events:\n",
    "        if event not in nullTextDf.index:\n",
    "            nullTextDf.loc[event] = {'postText':False, 'text':False, 'full_text':False}\n",
    "        nullTextDf.loc[event][textVar] = True\n",
    "\n",
    "print(nullTextDf.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.postID.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df=full_df.drop_duplicates(subset=['postID'])\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine text into PostText\n",
    "full_df['postText'] = full_df['postText'].fillna(full_df['text'])\n",
    "full_df['postText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove null text values\n",
    "full_df = full_df[(~full_df[\"postText\"].isnull())]\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save full_df\n",
    "full_df.to_json('./Trec_data/combined_labeled.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_json(\"./Trec_data/combined_labeled.json\", orient='records',lines=True)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contributors',\n",
       " 'contributorsIDs',\n",
       " 'coordinates',\n",
       " 'createdAt',\n",
       " 'created_at',\n",
       " 'currentUserRetweetId',\n",
       " 'displayTextRangeEnd',\n",
       " 'displayTextRangeStart',\n",
       " 'display_text_range',\n",
       " 'entities',\n",
       " 'eventID',\n",
       " 'eventType',\n",
       " 'extended_entities',\n",
       " 'extended_tweet',\n",
       " 'favoriteCount',\n",
       " 'favorite_count',\n",
       " 'favorited',\n",
       " 'filter_level',\n",
       " 'full_text',\n",
       " 'geo',\n",
       " 'geoLocation',\n",
       " 'hashtagEntities',\n",
       " 'id',\n",
       " 'id_str',\n",
       " 'inReplyToScreenName',\n",
       " 'inReplyToStatusId',\n",
       " 'inReplyToUserId',\n",
       " 'in_reply_to_screen_name',\n",
       " 'in_reply_to_status_id',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'isFavorited',\n",
       " 'isPossiblySensitive',\n",
       " 'isRetweeted',\n",
       " 'isTruncated',\n",
       " 'is_quote_status',\n",
       " 'lang',\n",
       " 'matching_rules',\n",
       " 'mediaEntities',\n",
       " 'metadata',\n",
       " 'place',\n",
       " 'possibly_sensitive',\n",
       " 'possibly_sensitive_appealable',\n",
       " 'postCategories',\n",
       " 'postID',\n",
       " 'postPriority',\n",
       " 'postText',\n",
       " 'quote_count',\n",
       " 'quotedStatus',\n",
       " 'quotedStatusId',\n",
       " 'quoted_status',\n",
       " 'quoted_status_id',\n",
       " 'quoted_status_id_str',\n",
       " 'quoted_status_permalink',\n",
       " 'reply_count',\n",
       " 'retweetCount',\n",
       " 'retweet_count',\n",
       " 'retweeted',\n",
       " 'retweeted_status',\n",
       " 'scopes',\n",
       " 'source',\n",
       " 'symbolEntities',\n",
       " 'text',\n",
       " 'timestamp_ms',\n",
       " 'topic',\n",
       " 'truncated',\n",
       " 'urlEntities',\n",
       " 'user',\n",
       " 'userMentionEntities',\n",
       " 'withheld_in_countries']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder columns\n",
    "cols = ['eventID',\n",
    " 'eventType',\n",
    " 'postID',\n",
    " 'postCategories',\n",
    " 'postPriority',\n",
    " 'postText',\n",
    " 'contributors',\n",
    " 'contributorsIDs',\n",
    " 'coordinates',\n",
    " 'createdAt',\n",
    " 'created_at',\n",
    " 'currentUserRetweetId',\n",
    " 'displayTextRangeEnd',\n",
    " 'displayTextRangeStart',\n",
    " 'display_text_range',\n",
    " 'entities',\n",
    " 'extended_entities',\n",
    " 'extended_tweet',\n",
    " 'favoriteCount',\n",
    " 'favorite_count',\n",
    " 'favorited',\n",
    " 'filter_level',\n",
    " 'full_text',\n",
    " 'geo',\n",
    " 'geoLocation',\n",
    " 'hashtagEntities',\n",
    " 'id',\n",
    " 'id_str',\n",
    " 'inReplyToScreenName',\n",
    " 'inReplyToStatusId',\n",
    " 'inReplyToUserId',\n",
    " 'in_reply_to_screen_name',\n",
    " 'in_reply_to_status_id',\n",
    " 'in_reply_to_status_id_str',\n",
    " 'in_reply_to_user_id',\n",
    " 'in_reply_to_user_id_str',\n",
    " 'isFavorited',\n",
    " 'isPossiblySensitive',\n",
    " 'isRetweeted',\n",
    " 'isTruncated',\n",
    " 'is_quote_status',\n",
    " 'lang',\n",
    " 'matching_rules',\n",
    " 'mediaEntities',\n",
    " 'metadata',\n",
    " 'place',\n",
    " 'possibly_sensitive',\n",
    " 'possibly_sensitive_appealable',\n",
    " 'quote_count',\n",
    " 'quotedStatus',\n",
    " 'quotedStatusId',\n",
    " 'quoted_status',\n",
    " 'quoted_status_id',\n",
    " 'quoted_status_id_str',\n",
    " 'quoted_status_permalink',\n",
    " 'reply_count',\n",
    " 'retweetCount',\n",
    " 'retweet_count',\n",
    " 'retweeted',\n",
    " 'retweeted_status',\n",
    " 'scopes',\n",
    " 'source',\n",
    " 'symbolEntities',\n",
    " 'text',\n",
    " 'timestamp_ms',\n",
    " 'topic',\n",
    " 'truncated',\n",
    " 'urlEntities',\n",
    " 'user',\n",
    " 'userMentionEntities',\n",
    " 'withheld_in_countries'\n",
    "    ]\n",
    "full_df = full_df[cols]\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventTypes = df['eventType'].unique()\n",
    "for event in eventTypes:\n",
    "    eventsDF = df.loc[df['eventType']==event]['eventID'].unique()\n",
    "    events = full_df.loc[full_df['eventType']==event]['eventID'].unique()\n",
    "    print(event + ': ' + str(eventsDF.size) + ' : ' + str(events.size))\n",
    "    print(eventsDF)\n",
    "    print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save organized full_df, This df also goes to analyse_data notebook\n",
    "full_df.to_json('./Trec_data/org_combined_labeled.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_json(\"./Trec_data/org_combined_labeled.json\", orient='records',lines=True)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove certain non-neccessary columns\n",
    "cols = ['eventID',\n",
    " 'eventType',\n",
    " 'postID',\n",
    " 'postCategories',\n",
    " 'postPriority',\n",
    " 'postText',\n",
    " #'contributors',\n",
    " #'contributorsIDs',\n",
    " #'coordinates', #Not useful for\n",
    " #'createdAt', #When there is two of these it tends to be a list of dtype and of objects\n",
    " #'created_at',\n",
    " #'currentUserRetweetId',\n",
    " #'displayTextRangeEnd', #Unsure how these three variables could be useful\n",
    " #'displayTextRangeStart',\n",
    " #'display_text_range',\n",
    " 'entities',\n",
    " 'extended_entities',\n",
    " #'extended_tweet',\n",
    " 'favorite_count',\n",
    " #'filter_level', #Low variability\n",
    " #'geo',\n",
    " #'geoLocation',\n",
    " 'hashtagEntities',\n",
    " 'inReplyToScreenName',\n",
    " 'inReplyToStatusId',\n",
    " 'inReplyToUserId',\n",
    " #'in_reply_to_screen_name',\n",
    " #'in_reply_to_status_id',\n",
    " #'in_reply_to_status_id_str',\n",
    " #'in_reply_to_user_id',\n",
    " #'in_reply_to_user_id_str',\n",
    " 'isFavorited',\n",
    " #'isPossiblySensitive', #Applies to 14 rows\n",
    " 'isRetweeted',\n",
    " 'isTruncated',\n",
    " 'is_quote_status',\n",
    " 'lang',\n",
    " 'matching_rules',\n",
    " 'mediaEntities',\n",
    " 'metadata',\n",
    " #'place', #Could be really useful, containes a lot of location data, for now disabled because its too much info and also low reliability\n",
    " 'possibly_sensitive', #Might have value\n",
    " #'possibly_sensitive_appealable',\n",
    " #'quote_count',\n",
    " #'quotedStatus',\n",
    " #'quotedStatusId',\n",
    " #'quoted_status',\n",
    " #'quoted_status_id',\n",
    " #'quoted_status_id_str',\n",
    " #'quoted_status_permalink',\n",
    " #'reply_count',\n",
    " 'retweet_count', #Utilize to replace if retweeted, maybe use to double check retweeted_status\n",
    " #'retweeted',\n",
    " 'retweeted_status',\n",
    " #'scopes', #Only NaN values\n",
    " #'source', No clue how this may be utilized\n",
    " #'symbolEntities',\n",
    " #'timestamp_ms', #Time series bad\n",
    " #'topic', #Same as eventID pretty much, I think\n",
    " 'truncated', #Useful, mark NaN as 0 and switch to boolean?\n",
    " #'urlEntities', #Has information regarding urls\n",
    " 'user' #Very useful but there is a lot of associated data\n",
    " #'userMentionEntities', #Useful somehow i'm sure just don't know right now\n",
    " #'withheld_in_countries' #Only relates to 4 tweets\n",
    "       ]\n",
    "full_df = full_df[cols]\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_json(\"./Trec_data/Feature_Reduction.json\", orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_json(\"./Trec_data/Feature_Reduction.json\", orient='records',lines=True)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Additional Features\n",
    "local_tokenizer = TweetTokenizer()\n",
    "def tokenizer_wrapper(text):\n",
    "    return local_tokenizer.tokenize(text)\n",
    "\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    #return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "    return(parsed_text)\n",
    "\n",
    "\n",
    "other_features_names = [\"num_chars\", \"num_chars_total\", \n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\", \"vader pos\",\n",
    "                        \"vader neu\", \"vader compound\", \n",
    "                        \"num_hashtags\", \"num_mentions\", \n",
    "                        \"num_urls\", \n",
    "                        \"is_retweet\", \"num_media\",\n",
    "                        \"is_verified\", \n",
    "                        \"caps_ratio\"]\n",
    "\n",
    "## Taken from Davidson et al.\n",
    "def other_features(data):\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    for index, tweet in tqdm(data.iterrows(), total=data.shape[0], position=0, leave=True):\n",
    "        #print(tweet)\n",
    "        \"\"\"This function takes a string and returns a list of features.\n",
    "        These include Sentiment scores, Text and Readability scores,\n",
    "        as well as Twitter specific features\"\"\"\n",
    "        tweet_text = tweet[\"postText\"]\n",
    "\n",
    "        ##SENTIMENT\n",
    "        sentiment = sentiment_analyzer.polarity_scores(tweet_text)\n",
    "\n",
    "        words = local_tokenizer.tokenize(tweet_text) #Get text only\n",
    "\n",
    "        num_chars = sum(len(w) for w in words) #num chars in words\n",
    "        num_chars_total = len(tweet_text)\n",
    "        num_terms = len(tweet_text.split())\n",
    "        num_words = len(words)\n",
    "        num_unique_terms = len(set([x.lower() for x in words]))\n",
    "\n",
    "        caps_count = sum([1 if x.isupper() else 0 for x in tweet_text])\n",
    "        caps_ratio = caps_count / num_chars_total\n",
    "\n",
    "        parsed_text = count_twitter_objs(tweet_text) #Count #, @, and http://\n",
    "        twitter_objs = (parsed_text.count('URLHERE'), parsed_text.count('MENTIONHERE'), parsed_text.count('HASHTAGHERE'))\n",
    "        num_media = 0\n",
    "        if \"entities\" in tweet and tweet[\"entities\"] != None and \"media\" in tweet[\"entities\"]:\n",
    "                num_media = len(tweet[\"entities\"][\"media\"])\n",
    "        retweet = 0\n",
    "        if \"rt\" in words or \"retweeted_status\" in tweet:\n",
    "            retweet = 1\n",
    "        \n",
    "\n",
    "        has_place = 1 if \"coordinates\" in tweet else 0\n",
    "\n",
    "        author = tweet[\"user\"]\n",
    "        is_verified = 1 if (\"verified\" in author and author[\"verified\"]) else 0\n",
    "        \n",
    "        features = [num_chars, num_chars_total, num_terms, num_words, num_unique_terms,\n",
    "                    sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                    twitter_objs[2], twitter_objs[1], twitter_objs[0],\n",
    "                    retweet, num_media, is_verified, caps_ratio]\n",
    "        \n",
    "        \n",
    "        features = [round(x, 4) for x in features]\n",
    "        \n",
    "        new_row = {}\n",
    "        for feature, name in zip(features, other_features_names):\n",
    "            new_row[name] = feature\n",
    "        \n",
    "        #new_row['postID'] = tweet['postID']\n",
    "        \n",
    "        new_df = new_df.append(new_row, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating extra features\n",
    "other_ftr_df = other_features(full_df)\n",
    "other_ftr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Combine the extra features into original database\n",
    "featured_df = pd.concat([full_df, other_ftr_df], axis=1)\n",
    "featured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sentence embedding\n",
    "class SBERT:\n",
    "\n",
    "    def __init__(self, lang=\"en\"):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        self.name = \"SBERT\"\n",
    "        if lang == \"fr\":\n",
    "            self.model = SentenceTransformer(\n",
    "                \"/home/bmazoyer/Dev/pytorch_bert/output/sts_fr_long_multilingual_bert-2019-10-01_15-07-03\")\n",
    "        elif lang == \"en\": #Does this need to be changed?\n",
    "            self.model = SentenceTransformer(\n",
    "                # \"bert-large-nli-stsb-mean-tokens\"\n",
    "                \"roberta-large-nli-stsb-mean-tokens\"\n",
    "            )\n",
    "# roberta-large-nli-stsb-mean-tokens\n",
    "    def compute_vectors(self, data):\n",
    "        data[\"postText\"] = data.postText.str.slice(0, 500)\n",
    "        vectors = np.array(self.model.encode(data.postText.tolist()))\n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert=SBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore for now\n",
    "v=sbert.compute_vectors(featured_df) #Takes ages\n",
    "featured_df['vectorized_text']=[item for item in tqdm(v)]\n",
    "featured_df['vectorized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save new df\n",
    "featured_df.to_json(\"./Trec_data/Features_Labeled.json\", orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_df = pd.read_json(\"./Trec_data/Features_Labeled.json\", orient='records',lines=True)\n",
    "featured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change priority target, might not be needed\n",
    "priorityDict = {'Unknown':0.0, 'Low':0.25, 'Medium':.5, 'High':.75, 'Critical':1}\n",
    "featured_df['regression_priority']=[priorityDict[item] for item in featured_df['postPriority']]\n",
    "featured_df[['regression_priority', 'postPriority']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change categories to be multiple boolean columns\n",
    "#categories = featured_df['postCategories'].explode().unique()\n",
    "#cat_df = pd.DataFrame(index=np.arange(featured_df.shape[0]))\n",
    "#for cat in categories:\n",
    "#    name = 'bool_' + cat\n",
    "#    cat_df[name] = False\n",
    "#for index, row in tqdm(featured_df.iterrows(), total=data.shape[0], position=0, leave=True):\n",
    "#    for cat in row['postCategories']:\n",
    "#        cat_df.loc[index]['bool_' + cat] = True\n",
    "#featured_df = pd.concat([featured_df, cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switch from multiple boolean columns to MultiLabelBinarizer\n",
    "categories = MultiLabelBinarizer().fit_transform(featured_df['postCategories']) #this should yield 25 in second dimension\n",
    "print(type(categories))\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with featured_df\n",
    "featured_df['sparseCategories'] = categories.tolist()\n",
    "featured_df['sparseCategories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save new df\n",
    "featured_df.to_json(\"./Trec_data/Preprocessed_labelled.json\", orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load new df to skip above processes\n",
    "featured_df = pd.read_json(\"./Trec_data/Preprocessed_labelled.json\", orient='records',lines=True)\n",
    "featured_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
