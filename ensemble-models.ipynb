{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g/g01107/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, cohen_kappa_score, precision_score, recall_score, \\\n",
    "    precision_recall_curve\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.base import clone\n",
    "from scipy import stats\n",
    "import sklearn.preprocessing\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import base_dir\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventID</th>\n",
       "      <th>eventType</th>\n",
       "      <th>postID</th>\n",
       "      <th>postCategories</th>\n",
       "      <th>postPriority</th>\n",
       "      <th>postText</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>hashtagEntities</th>\n",
       "      <th>...</th>\n",
       "      <th>num_terms</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_words</th>\n",
       "      <th>vader compound</th>\n",
       "      <th>vader neg</th>\n",
       "      <th>vader neu</th>\n",
       "      <th>vader pos</th>\n",
       "      <th>regression_priority</th>\n",
       "      <th>sparseCategories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fireColorado2012</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>212365530391252993</td>\n",
       "      <td>[Factoid]</td>\n",
       "      <td>Low</td>\n",
       "      <td>The High Park fire west of Fort Collins, #CO h...</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [{'tex...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fireColorado2012</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>217744670753689603</td>\n",
       "      <td>[MultimediaShare]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Pic of the #FlagstaffFire in boulder from our ...</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [{'tex...</td>\n",
       "      <td>{'media': [{'sizes': {'small': {'w': 510, 'res...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fireColorado2012</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>212311994286620672</td>\n",
       "      <td>[MultimediaShare]</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>RT @CBSDenver: The copter is on the way to the...</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [{'tex...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fireColorado2012</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>217030749856088066</td>\n",
       "      <td>[]</td>\n",
       "      <td>Low</td>\n",
       "      <td>I have it on good authority that most of Color...</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [], 'u...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fireColorado2012</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>217746356842926080</td>\n",
       "      <td>[MultimediaShare]</td>\n",
       "      <td>Medium</td>\n",
       "      <td>RT @ColoradoRapids: Photo of #FlagStaffFire in...</td>\n",
       "      <td>{'symbols': [], 'urls': [], 'hashtags': [{'tex...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72468</th>\n",
       "      <td>covidNewZealand2020</td>\n",
       "      <td>covid</td>\n",
       "      <td>1296006183178784768</td>\n",
       "      <td>[FirstPartyObservation, MultimediaShare, Advice]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Its personal choice to wear a mask\\nDon't put ...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 1296006181022916608, 'id_str...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72469</th>\n",
       "      <td>covidNewZealand2020</td>\n",
       "      <td>covid</td>\n",
       "      <td>1296214212046237698</td>\n",
       "      <td>[Irrelevant]</td>\n",
       "      <td>Low</td>\n",
       "      <td>The Government did the right thing. They shoul...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72470</th>\n",
       "      <td>houstonExplosion2020</td>\n",
       "      <td>explosion</td>\n",
       "      <td>1220704310520094720</td>\n",
       "      <td>[ThirdPartyObservation, Location, EmergingThre...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Um. Jon? You get jolted awake early this morni...</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72471</th>\n",
       "      <td>texasAMCommerceShooting2020</td>\n",
       "      <td>shooting</td>\n",
       "      <td>1224419435043123200</td>\n",
       "      <td>[ThirdPartyObservation, Location, MultimediaSh...</td>\n",
       "      <td>Low</td>\n",
       "      <td>2 dead, 1 hurt in shooting at college residenc...</td>\n",
       "      <td>{'hashtags': [{'text': 'SmartNews', 'indices':...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.8271</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72472</th>\n",
       "      <td>tennesseeTornadoOutbreak2020</td>\n",
       "      <td>tornado</td>\n",
       "      <td>1234775917148413953</td>\n",
       "      <td>[ThirdPartyObservation, Weather, Location]</td>\n",
       "      <td>Low</td>\n",
       "      <td>Early morning tornado in Nashville,TN ? https:...</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72473 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            eventID  eventType               postID  \\\n",
       "0                  fireColorado2012   wildfire   212365530391252993   \n",
       "1                  fireColorado2012   wildfire   217744670753689603   \n",
       "2                  fireColorado2012   wildfire   212311994286620672   \n",
       "3                  fireColorado2012   wildfire   217030749856088066   \n",
       "4                  fireColorado2012   wildfire   217746356842926080   \n",
       "...                             ...        ...                  ...   \n",
       "72468           covidNewZealand2020      covid  1296006183178784768   \n",
       "72469           covidNewZealand2020      covid  1296214212046237698   \n",
       "72470          houstonExplosion2020  explosion  1220704310520094720   \n",
       "72471   texasAMCommerceShooting2020   shooting  1224419435043123200   \n",
       "72472  tennesseeTornadoOutbreak2020    tornado  1234775917148413953   \n",
       "\n",
       "                                          postCategories postPriority  \\\n",
       "0                                              [Factoid]          Low   \n",
       "1                                      [MultimediaShare]          Low   \n",
       "2                                      [MultimediaShare]      Unknown   \n",
       "3                                                     []          Low   \n",
       "4                                      [MultimediaShare]       Medium   \n",
       "...                                                  ...          ...   \n",
       "72468   [FirstPartyObservation, MultimediaShare, Advice]          Low   \n",
       "72469                                       [Irrelevant]          Low   \n",
       "72470  [ThirdPartyObservation, Location, EmergingThre...          Low   \n",
       "72471  [ThirdPartyObservation, Location, MultimediaSh...          Low   \n",
       "72472         [ThirdPartyObservation, Weather, Location]          Low   \n",
       "\n",
       "                                                postText  \\\n",
       "0      The High Park fire west of Fort Collins, #CO h...   \n",
       "1      Pic of the #FlagstaffFire in boulder from our ...   \n",
       "2      RT @CBSDenver: The copter is on the way to the...   \n",
       "3      I have it on good authority that most of Color...   \n",
       "4      RT @ColoradoRapids: Photo of #FlagStaffFire in...   \n",
       "...                                                  ...   \n",
       "72468  Its personal choice to wear a mask\\nDon't put ...   \n",
       "72469  The Government did the right thing. They shoul...   \n",
       "72470  Um. Jon? You get jolted awake early this morni...   \n",
       "72471  2 dead, 1 hurt in shooting at college residenc...   \n",
       "72472  Early morning tornado in Nashville,TN ? https:...   \n",
       "\n",
       "                                                entities  \\\n",
       "0      {'symbols': [], 'urls': [], 'hashtags': [{'tex...   \n",
       "1      {'symbols': [], 'urls': [], 'hashtags': [{'tex...   \n",
       "2      {'symbols': [], 'urls': [], 'hashtags': [{'tex...   \n",
       "3      {'symbols': [], 'urls': [], 'hashtags': [], 'u...   \n",
       "4      {'symbols': [], 'urls': [], 'hashtags': [{'tex...   \n",
       "...                                                  ...   \n",
       "72468  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "72469  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "72470  {'hashtags': [], 'urls': [{'url': 'https://t.c...   \n",
       "72471  {'hashtags': [{'text': 'SmartNews', 'indices':...   \n",
       "72472  {'hashtags': [], 'urls': [], 'user_mentions': ...   \n",
       "\n",
       "                                       extended_entities  favorite_count  \\\n",
       "0                                                   None             0.0   \n",
       "1      {'media': [{'sizes': {'small': {'w': 510, 'res...             0.0   \n",
       "2                                                   None             0.0   \n",
       "3                                                   None             0.0   \n",
       "4                                                   None             0.0   \n",
       "...                                                  ...             ...   \n",
       "72468  {'media': [{'id': 1296006181022916608, 'id_str...            19.0   \n",
       "72469                                               None             1.0   \n",
       "72470                                               None             0.0   \n",
       "72471                                               None             0.0   \n",
       "72472                                               None             0.0   \n",
       "\n",
       "      hashtagEntities  ... num_terms  num_unique_words  num_urls  num_words  \\\n",
       "0                None  ...        25                28         0         29   \n",
       "1                None  ...        10                11         1         11   \n",
       "2                None  ...        25                25         0         28   \n",
       "3                None  ...        26                29         0         32   \n",
       "4                None  ...        23                25         0         26   \n",
       "...               ...  ...       ...               ...       ...        ...   \n",
       "72468            None  ...        24                21         1         24   \n",
       "72469            None  ...        16                16         1         18   \n",
       "72470            None  ...        10                12         1         13   \n",
       "72471            None  ...        12                13         1         13   \n",
       "72472            None  ...         7                 9         1          9   \n",
       "\n",
       "       vader compound  vader neg  vader neu vader pos regression_priority  \\\n",
       "0             -0.3400      0.091      0.909     0.000                0.25   \n",
       "1              0.0000      0.000      1.000     0.000                0.25   \n",
       "2              0.0000      0.000      1.000     0.000                0.00   \n",
       "3              0.0552      0.177      0.610     0.214                0.25   \n",
       "4              0.0000      0.000      1.000     0.000                0.50   \n",
       "...               ...        ...        ...       ...                 ...   \n",
       "72468         -0.3412      0.099      0.901     0.000                0.25   \n",
       "72469         -0.0516      0.173      0.663     0.163                0.25   \n",
       "72470          0.0000      0.000      1.000     0.000                0.25   \n",
       "72471         -0.8271      0.490      0.510     0.000                0.25   \n",
       "72472          0.0000      0.000      1.000     0.000                0.25   \n",
       "\n",
       "                                        sparseCategories  \n",
       "0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "...                                                  ...  \n",
       "72468  [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "72469  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "72470  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, ...  \n",
       "72471  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, ...  \n",
       "72472  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "\n",
       "[72473 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe  generated in analye-data.ipynb\n",
    "df = pd.read_json(\"Trec_data/Preprocessed_labelled.json\", orient='records', lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Generate Event Types`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wildfire', 'earthquake', 'flood', 'typhoon', 'shooting', 'bombing', 'covid', 'explosion', 'storm']\n"
     ]
    }
   ],
   "source": [
    "fullEventTypes = df['eventType'].unique()\n",
    "eventTypes = []\n",
    "for event in fullEventTypes:\n",
    "    events = df.loc[df['eventType'] == event]['eventID'].unique()\n",
    "    if events.size > 1:\n",
    "        eventTypes.append(event)\n",
    "print(eventTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Event Ensembles\n",
    "EventEnsembles = {}\n",
    "EventEnsembles['wildfire'] = ['wildfire', 'flood', 'typhoon']\n",
    "EventEnsembles['earthquake'] = ['earthquake', 'typhoon', 'flood']\n",
    "EventEnsembles['flood'] = ['flood', 'typhoon', 'storm']\n",
    "EventEnsembles['typhoon'] = ['typhoon', 'flood', 'storm']\n",
    "EventEnsembles['shooting'] = ['shooting', 'flood', 'wildfire']\n",
    "EventEnsembles['bombing'] = ['bombing', '', ''] #Need to go back to fix sim matrixes\n",
    "EventEnsembles['covid'] = ['covid', '', '']\n",
    "EventEnsembles['explosion'] = ['explosion', '', '']\n",
    "EventEnsembles['storm'] = ['storm', 'flood', 'typhoon'] #Same as typhoon input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Model Related Methods`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(data, column, heldout_ids):\n",
    "    if type(heldout_ids) != list:\n",
    "        heldout_ids = [heldout_ids]\n",
    "    training = data.loc[~data[column].isin(heldout_ids)]\n",
    "    \n",
    "    return training\n",
    "\n",
    "def test_data(data, column, heldout_ids):\n",
    "    if type(heldout_ids) != list:\n",
    "        heldout_ids = [heldout_ids]\n",
    "    test = data.loc[data[column].isin(heldout_ids)]\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently unused\n",
    "def save_model(model, filename):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "def load_model(filename):\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Generate Generic Variables`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"num_chars\", \"num_chars_total\", \n",
    "            \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\", \"vader pos\",\n",
    "            \"vader neu\", \"vader compound\", \n",
    "            \"num_hashtags\", \"num_mentions\", \n",
    "            \"num_urls\", \n",
    "            \"is_retweet\", \"num_media\",\n",
    "            \"is_verified\", \n",
    "            \"caps_ratio\"]\n",
    "\n",
    "#I think you need to make a list of lists\n",
    "\n",
    "rf_params = {\n",
    "    'random_state': 1337,\n",
    "    'class_weight': 'balanced',\n",
    "    'n_estimators': 128, \n",
    "    'n_jobs': -1,\n",
    "    'max_depth': 50,\n",
    "    'max_features': 14,\n",
    "    'min_samples_leaf': 33,\n",
    "    'min_samples_split': 96,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Generate and Test postPriority Models`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_scores_by_event_Prio(data, event, features, target, modelType):\n",
    "    f1_accum = []\n",
    "    accuracy_accum = []\n",
    "    \n",
    "    labels = data[target].unique()\n",
    "    label_f1_accum = {} #Dict by unique labels\n",
    "    label_score_accum = {}\n",
    "    for label in labels:\n",
    "        label_f1_accum[label] = []\n",
    "        label_score_accum[label] = []\n",
    "    \n",
    "    eventIDs = data.loc[data['eventType']==event]['eventID'].unique()\n",
    "    for heldoutEvent in tqdm(eventIDs, position=1,desc=event):\n",
    "        #Create training and test dataframe\n",
    "        training = train_data(data, 'eventID', heldoutEvent)\n",
    "        test = test_data(data, 'eventID', heldoutEvent)\n",
    "        \n",
    "        X_train = training[features]\n",
    "        y_train = training[target]        \n",
    "        X_test = test[features]\n",
    "        y_test = test[target]\n",
    "        \n",
    "        if isinstance(y_train, pd.Series):\n",
    "            y_train = []\n",
    "            for val in training[target]:\n",
    "                y_train.append(np.array(val))\n",
    "            y_train= np.array(y_train)\n",
    "        if isinstance(y_test, pd.Series):\n",
    "            y_test = []\n",
    "            for val in test[target]:\n",
    "                y_test.append(np.array(val))\n",
    "            y_test= np.array(y_test)\n",
    "            \n",
    "        \n",
    "        #generate model\n",
    "        model = clone(modelType)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #Test model\n",
    "        y_infer_local = model.predict(X_test)\n",
    "        local_f1 = f1_score(y_test, y_infer_local, average=\"macro\", zero_division=0)\n",
    "        local_score = model.score(X_test, y_test)\n",
    "        \n",
    "        accuracy_accum.append(local_score)\n",
    "        f1_accum.append(local_f1)\n",
    "        \n",
    "        #Seperate scores per label\n",
    "        for label in labels:\n",
    "            label_ids = test[target]==label\n",
    "            x_label = X_test[label_ids]\n",
    "            y_label = y_test[label_ids]\n",
    "            y_infer_label = y_infer_local[label_ids]\n",
    "            \n",
    "            if x_label.size == 0:\n",
    "                continue\n",
    "            \n",
    "            label_f1 = f1_score(y_label, y_infer_label, average=\"macro\", zero_division=0)\n",
    "            label_score = model.score(x_label, y_label)\n",
    "            \n",
    "            label_f1_accum[label].append(label_f1)\n",
    "            label_score_accum[label].append(label_score)\n",
    "        \n",
    "        \n",
    "    for label in labels: #Prevent blank\n",
    "        if len(label_f1_accum[label])==0:\n",
    "            label_f1_accum.pop(label, None)\n",
    "            label_score_accum.pop(label, None)\n",
    "        \n",
    "    return [accuracy_accum, f1_accum, label_score_accum, label_f1_accum] #Accuracy is 0, F1 is 1, label Acc is 2, label F1 is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prioLabel = 'postPriority'\n",
    "prioModel = RandomForestClassifier(**rf_params)\n",
    "\n",
    "#genPrioScores = {}\n",
    "ensPrioScores = {}\n",
    "\n",
    "#generate general model\n",
    "for event in tqdm(eventTypes, position=0, desc='Events'):\n",
    "    #print('Event: ' + event)\n",
    "    eventDF = df.loc[df['eventType'].isin(EventEnsembles[event])]\n",
    "    #genPrioScores[event] = generate_scores_by_event_Prio(df, event, features, prioLabel, prioModel)\n",
    "    ensPrioScores[event] = generate_scores_by_event_Prio(eventDF, event, features, prioLabel, prioModel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Store prio scores in readable format\n",
    "labels = ['Low', 'Medium', 'High', 'Critical']\n",
    "\n",
    "prioEnsScoreDf = pd.DataFrame()#columns=cols)\n",
    "for event in eventTypes:\n",
    "    row = pd.Series(\n",
    "        {\n",
    "            'ensScores': ensPrioScores[event][0:1],\n",
    "            'ensLabelScores': ensPrioScores[event][2:3],\n",
    "            'avgAccEns': np.mean(ensPrioScores[event][0]),\n",
    "            'avgF1Ens': np.mean(ensPrioScores[event][1]),\n",
    "            'semAccEns': stats.sem(ensPrioScores[event][0]),\n",
    "            'semF1Ens': stats.sem(ensPrioScores[event][1])\n",
    "        }, name=event)\n",
    "    #Add label specific columns\n",
    "    for label in labels:\n",
    "        if label in label in ensPrioScores[event][2]:\n",
    "            labelCol = pd.Series(\n",
    "                {\n",
    "                    'avgAccEns' + label: np.mean(ensPrioScores[event][2][label]),\n",
    "                    'avgF1Ens' + label: np.mean(ensPrioScores[event][3][label]),\n",
    "                    'semAccEns' + label: stats.sem(ensPrioScores[event][2][label]),\n",
    "                    'semF1Ens' + label: stats.sem(ensPrioScores[event][3][label])\n",
    "                })\n",
    "            row = row.append(labelCol)\n",
    "    row.name = event\n",
    "    prioEnsScoreDf = prioEnsScoreDf.append(row)\n",
    "    \n",
    "#Reorder for easy readability\n",
    "cols = ['ensScores', 'ensLabelScores']\n",
    "scoreTypes = ['F1', 'Acc']\n",
    "accumTypes = ['avg', 'sem']\n",
    "testTypes = ['Ens']\n",
    "\n",
    "for score in scoreTypes:\n",
    "    for accum in accumTypes:\n",
    "        for test in testTypes:\n",
    "            cols.append(accum+score+test)\n",
    "            for label in labels:\n",
    "                cols.append(accum+score+test+label)\n",
    "\n",
    "print(cols)\n",
    "prioEnsScoreDf = prioEnsScoreDf[cols]\n",
    "prioEnsScoreDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prioScoreDf = pd.read_json(\"Trec_data/prioScoreDF.json\")\n",
    "prioScoreDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prioBothScoreDf = pd.concat([prioScoreDf, prioEnsScoreDf], axis=1)\n",
    "prioBothScoreDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save prio scores\n",
    "prioBothScoreDf.to_json(\"Trec_data/prioScoreDF.json\")\n",
    "\n",
    "filename = 'Trec_data/prio_results.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(prioBothScoreDf, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prioBothScoreDf = pd.read_json(\"Trec_data/prioScoreDF.json\")\n",
    "prioBothScoreDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Generate and Test postCategories Models`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_scores_by_event_Cat(data, event, features, target, modelType):\n",
    "    f1_accum = []\n",
    "    accuracy_accum = []\n",
    "    \n",
    "    eventIDs = data.loc[data['eventType']==event]['eventID'].unique()\n",
    "    for heldoutEvent in tqdm(eventIDs, position=1,desc=event):\n",
    "        #Create training and test dataframe\n",
    "        training = train_data(data, 'eventID', heldoutEvent)\n",
    "        test = test_data(data, 'eventID', heldoutEvent)\n",
    "        \n",
    "        X_train = training[features]\n",
    "        #y_train = training[target]        \n",
    "        X_test = test[features]\n",
    "        #y_test = test[target]\n",
    "        \n",
    "        y_train = []\n",
    "        for val in training[target]:\n",
    "            y_train.append(np.array(val))\n",
    "        y_train= np.array(y_train)\n",
    "            \n",
    "        y_test = []\n",
    "        for val in test[target]:\n",
    "            y_test.append(np.array(val))\n",
    "        y_test= np.array(y_test)\n",
    "            \n",
    "        \n",
    "        #generate model\n",
    "        model = clone(modelType)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #Test model\n",
    "        y_infer_local = model.predict(X_test)\n",
    "        local_f1 = f1_score(y_test, y_infer_local, average=\"macro\", zero_division=0)\n",
    "        local_score = model.score(X_test, y_test)\n",
    "        \n",
    "        accuracy_accum.append(local_score)\n",
    "        f1_accum.append(local_f1)\n",
    "        \n",
    "    return [accuracy_accum, f1_accum] #Accuracy is 0, F1 is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catLabel = 'sparseCategories'\n",
    "catModel = MultiOutputClassifier(RandomForestClassifier(**rf_params))\n",
    "\n",
    "#genCatScores = {}\n",
    "ensCatScores = {}\n",
    "\n",
    "#generate general model\n",
    "for event in tqdm(eventTypes, position=0, desc='Events'):\n",
    "    #print('Event: ' + event)\n",
    "    eventDF = df.loc[df['eventType'].isin(EventEnsembles[event])]\n",
    "    #genCatScores[event] = generate_scores_by_event_Cat(df, event, features, catLabel, catModel)\n",
    "    ensCatScores[event] = generate_scores_by_event_Cat(eventDF, event, features, catLabel, catModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Store cat scores in readable format\n",
    "catEnsScoreDf = pd.DataFrame(columns=['ensScores',\n",
    "                                   'avgAccEns', 'avgF1Ens',\n",
    "                                   'stdAccEns', 'stdF1Ens'])\n",
    "for event in eventTypes:\n",
    "    row = pd.Series(\n",
    "        {\n",
    "            'ensScores': ensCatScores[event],\n",
    "            'avgAccEns': np.mean(ensCatScores[event][0]),\n",
    "            'avgF1Ens': np.mean(ensCatScores[event][1]),\n",
    "            'stdAccEns': np.std(ensCatScores[event][0]),\n",
    "            'stdF1Ens': np.std(ensCatScores[event][1])\n",
    "        }, name=event)\n",
    "    catEnsScoreDf = catEnsScoreDf.append(row)\n",
    "    \n",
    "catEnsScoreDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catScoreDf = pd.read_json(\"Trec_data/catScoreDF.json\")\n",
    "catScoreDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the new data into the old data\n",
    "catBothScoreDf = pd.concat([catScoreDf, catEnsScoreDf], axis=1)\n",
    "catBothScoreDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cat scores\n",
    "catBothScoreDf.to_json(\"Trec_data/catScoreDF.json\")\n",
    "\n",
    "filename = 'Trec_data/cat_results.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(catBothScoreDf,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "catBothScoreDf = pd.read_json(\"Trec_data/catScoreDF.json\")\n",
    "catBothScoreDf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
